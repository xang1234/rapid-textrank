{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# rapid_textrank TestPyPI Demo\n",
        "\n",
        "This notebook installs the package from TestPyPI and runs a few quick examples.\n",
        "\n",
        "Notes:\n",
        "- If you already installed `rapid_textrank`, restart the kernel after running the install cell.\n",
        "- The examples below avoid spaCy dependencies; they use the Rust-backed Python API directly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.11/site-packages (26.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Looking in indexes: https://test.pypi.org/simple/, https://pypi.org/simple\n",
            "Collecting rapid_textrank==0.1.0\n",
            "  Using cached https://test-files.pythonhosted.org/packages/19/15/088e8c06cbfafc5f13b57f7890bbaa296a7b8739079e2fbf84bfce5eca43/rapid_textrank-0.1.0.tar.gz (78 kB)\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hBuilding wheels for collected packages: rapid_textrank\n",
            "  Building wheel for rapid_textrank (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for rapid_textrank: filename=rapid_textrank-0.1.0-cp311-cp311-macosx_10_12_x86_64.whl size=509821 sha256=0b939bfca5213629581e10aea97968855da06f43c651e42aa2ac97cea411d7fb\n",
            "  Stored in directory: /Users/admin/Library/Caches/pip/wheels/4a/58/58/6c8e409e6867621d7ac2546e31516290a895fe3480666bf066\n",
            "Successfully built rapid_textrank\n",
            "Installing collected packages: rapid_textrank\n",
            "Successfully installed rapid_textrank-0.1.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# Install from PyPI (production).\n",
        "%pip install -U pip\n",
        "%pip install rapid_textrank==0.0.1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rapid_textrank version: 0.1.0\n"
          ]
        }
      ],
      "source": [
        "from rapid_textrank import extract_keywords, BaseTextRank, PositionRank, BiasedTextRank, __version__\n",
        "\n",
        "print(\"rapid_textrank version:\", __version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 1. Machine                   0.2188\n",
            " 2. artificial intelligence that enables 0.2063\n",
            " 3. and improve from experience 0.1429\n",
            " 4. networks with many layers 0.1210\n",
            " 5. is a subset of            0.0742\n"
          ]
        }
      ],
      "source": [
        "# Example text (from this repo's README)\n",
        "text = \"\"\"\n",
        "Machine learning is a subset of artificial intelligence that enables\n",
        "systems to learn and improve from experience. Deep learning, a type of\n",
        "machine learning, uses neural networks with many layers.\n",
        "\"\"\"\n",
        "\n",
        "phrases = extract_keywords(text, top_n=5, language=\"en\")\n",
        "for p in phrases:\n",
        "    print(f\"{p.rank:>2}. {p.text:25s} {p.score:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BaseTextRank:\n",
            "- error correction and (0.3680)\n",
            "- reliable systems (0.3680)\n",
            "- larger more (0.2074)\n",
            "- Quantum (0.0283)\n",
            "- Researchers are (0.0283)\n",
            "\n",
            "PositionRank:\n",
            "- error correction and (0.2851)\n",
            "- reliable systems (0.2658)\n",
            "- Quantum (0.2533)\n",
            "- larger more (0.1536)\n",
            "- Researchers are (0.0422)\n",
            "\n",
            "BiasedTextRank (focus: security/privacy):\n",
            "- error correction and (0.3680)\n",
            "- reliable systems (0.3680)\n",
            "- larger more (0.2074)\n",
            "- Quantum (0.0283)\n",
            "- Researchers are (0.0283)\n"
          ]
        }
      ],
      "source": [
        "# Class-based API\n",
        "text2 = \"\"\"\n",
        "Quantum computing is advancing quickly. Researchers are improving\n",
        "error correction and building larger, more reliable systems.\n",
        "\"\"\"\n",
        "\n",
        "print(\"BaseTextRank:\")\n",
        "base = BaseTextRank(top_n=5, language=\"en\")\n",
        "for p in base.extract_keywords(text2).phrases:\n",
        "    print(f\"- {p.text} ({p.score:.4f})\")\n",
        "\n",
        "print(\"\\nPositionRank:\")\n",
        "pos = PositionRank(top_n=5, language=\"en\")\n",
        "for p in pos.extract_keywords(text2).phrases:\n",
        "    print(f\"- {p.text} ({p.score:.4f})\")\n",
        "\n",
        "print(\"\\nBiasedTextRank (focus: security/privacy):\")\n",
        "biased = BiasedTextRank(focus_terms=[\"security\", \"privacy\"], bias_weight=5.0, top_n=5)\n",
        "for p in biased.extract_keywords(text2).phrases:\n",
        "    print(f\"- {p.text} ({p.score:.4f})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 1. system of linear Diophantine        0.1562\n",
            " 2. systems and systems of              0.1205\n",
            " 3. and nonstrict inequations are       0.1110\n",
            " 4. over the set of                     0.1084\n",
            " 5. of solutions and algorithms         0.1065\n",
            " 6. of solutions can be                 0.0725\n",
            " 7. systems are given                   0.0602\n",
            " 8. types                               0.0516\n",
            " 9. for all types of                    0.0516\n",
            "10. for components of a                 0.0414\n"
          ]
        }
      ],
      "source": [
        "# Example text from the pytextrank README\n",
        "text3 = \"\"\"\n",
        "Compatibility of systems of linear constraints over the set of natural\n",
        "numbers. Criteria of compatibility of a system of linear Diophantine\n",
        "equations, strict inequations, and nonstrict inequations are considered.\n",
        "Upper bounds for components of a minimal set of solutions and algorithms\n",
        "of construction of minimal generating sets of solutions for all types of\n",
        "systems are given. These criteria and the corresponding algorithms for\n",
        "constructing a minimal supporting set of solutions can be used in solving\n",
        "all the considered types systems and systems of mixed types.\n",
        "\"\"\"\n",
        "\n",
        "phrases = extract_keywords(text3, top_n=10, language=\"en\")\n",
        "for p in phrases:\n",
        "    print(f\"{p.rank:>2}. {p.text:35s} {p.score:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Doc 0:\n",
            "- Machine learning (1.0000)\n",
            "Doc 1:\n"
          ]
        }
      ],
      "source": [
        "# JSON interface (batch)\n",
        "import json\n",
        "from rapid_textrank import extract_batch_from_json\n",
        "\n",
        "docs = [\n",
        "    {\n",
        "        \"tokens\": [\n",
        "            {\n",
        "                \"text\": \"Machine\",\n",
        "                \"lemma\": \"machine\",\n",
        "                \"pos\": \"NOUN\",\n",
        "                \"start\": 0,\n",
        "                \"end\": 7,\n",
        "                \"sentence_idx\": 0,\n",
        "                \"token_idx\": 0,\n",
        "                \"is_stopword\": False,\n",
        "            },\n",
        "            {\n",
        "                \"text\": \"learning\",\n",
        "                \"lemma\": \"learning\",\n",
        "                \"pos\": \"NOUN\",\n",
        "                \"start\": 8,\n",
        "                \"end\": 16,\n",
        "                \"sentence_idx\": 0,\n",
        "                \"token_idx\": 1,\n",
        "                \"is_stopword\": False,\n",
        "            },\n",
        "        ],\n",
        "        \"config\": {\"top_n\": 3}\n",
        "    },\n",
        "    {\n",
        "        \"tokens\": [\n",
        "            {\n",
        "                \"text\": \"Neural\",\n",
        "                \"lemma\": \"neural\",\n",
        "                \"pos\": \"ADJ\",\n",
        "                \"start\": 0,\n",
        "                \"end\": 6,\n",
        "                \"sentence_idx\": 0,\n",
        "                \"token_idx\": 0,\n",
        "                \"is_stopword\": False,\n",
        "            },\n",
        "            {\n",
        "                \"text\": \"networks\",\n",
        "                \"lemma\": \"network\",\n",
        "                \"pos\": \"NOUN\",\n",
        "                \"start\": 7,\n",
        "                \"end\": 15,\n",
        "                \"sentence_idx\": 0,\n",
        "                \"token_idx\": 1,\n",
        "                \"is_stopword\": False,\n",
        "            },\n",
        "        ]\n",
        "    },\n",
        "]\n",
        "\n",
        "results_json = extract_batch_from_json(json.dumps(docs))\n",
        "results = json.loads(results_json)\n",
        "\n",
        "for i, result in enumerate(results):\n",
        "    print(f\"Doc {i}:\")\n",
        "    for phrase in result[\"phrases\"]:\n",
        "        print(f\"- {phrase['text']} ({phrase['score']:.4f})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4e5e14d",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9938f41a",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}