{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title",
   "metadata": {},
   "source": [
    "# Algorithm Variants in rapid_textrank\n",
    "\n",
    "This notebook explores the three TextRank algorithm variants available in `rapid_textrank`:\n",
    "\n",
    "| Variant | Best For | Key Feature |\n",
    "|---------|----------|-------------|\n",
    "| **BaseTextRank** | General text | Standard TextRank implementation |\n",
    "| **PositionRank** | Academic papers, news | Favors words appearing early |\n",
    "| **BiasedTextRank** | Topic-focused extraction | Biases toward specified focus terms |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install if needed\n",
    "%pip install -q rapid_textrank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rapid_textrank import BaseTextRank, PositionRank, BiasedTextRank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "basetextrank-header",
   "metadata": {},
   "source": [
    "## 1. BaseTextRank\n",
    "\n",
    "The standard TextRank algorithm, based on [Mihalcea & Tarau (2004)](https://aclanthology.org/W04-3252/).\n",
    "\n",
    "**How it works:**\n",
    "1. Builds a co-occurrence graph from content words\n",
    "2. Runs PageRank to score word importance\n",
    "3. Extracts phrases by grouping high-scoring words\n",
    "\n",
    "**Best for:** General-purpose keyword extraction where word position doesn't matter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "basetextrank-example",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Natural language processing (NLP) is a field of artificial intelligence\n",
    "that focuses on the interaction between computers and humans through\n",
    "natural language. The ultimate goal of NLP is to enable computers to\n",
    "understand, interpret, and generate human language in a valuable way.\n",
    "\n",
    "Machine learning approaches have transformed NLP in recent years.\n",
    "Deep learning models, particularly transformers, have achieved\n",
    "state-of-the-art results on many NLP tasks including translation,\n",
    "summarization, and question answering.\n",
    "\"\"\"\n",
    "\n",
    "base = BaseTextRank(top_n=10, language=\"en\")\n",
    "result = base.extract_keywords(text)\n",
    "\n",
    "print(\"BaseTextRank Results:\")\n",
    "print(\"=\" * 50)\n",
    "for p in result.phrases:\n",
    "    print(f\"{p.rank:>2}. {p.text:<35} {p.score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "positionrank-header",
   "metadata": {},
   "source": [
    "## 2. PositionRank\n",
    "\n",
    "Based on [Florescu & Caragea (2017)](https://aclanthology.org/P17-1102/), PositionRank weights words by their position in the document.\n",
    "\n",
    "**Key insight:** In many documents (papers, news articles, reports), important terms appear early—in titles, abstracts, or introductory paragraphs.\n",
    "\n",
    "**How it differs from BaseTextRank:**\n",
    "- Words appearing early get higher initial importance\n",
    "- Position weight decays as you move through the document\n",
    "- The PageRank algorithm then refines these position-biased scores\n",
    "\n",
    "**Best for:** Academic papers, news articles, structured documents with front-loaded information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "positionrank-example",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Academic abstract where key terms appear in the title/first sentence\n",
    "abstract = \"\"\"\n",
    "Quantum Error Correction in Near-Term Quantum Computers\n",
    "\n",
    "We present a novel approach to quantum error correction that significantly\n",
    "reduces the overhead required for fault-tolerant quantum computation.\n",
    "Our method leverages machine learning to predict and correct errors\n",
    "in real-time. Experimental results on superconducting qubits demonstrate\n",
    "a 50% reduction in logical error rates. These advances bring us closer\n",
    "to practical quantum computing applications.\n",
    "\"\"\"\n",
    "\n",
    "pos = PositionRank(top_n=10, language=\"en\")\n",
    "result = pos.extract_keywords(abstract)\n",
    "\n",
    "print(\"PositionRank Results:\")\n",
    "print(\"=\" * 50)\n",
    "for p in result.phrases:\n",
    "    print(f\"{p.rank:>2}. {p.text:<35} {p.score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparison-header",
   "metadata": {},
   "source": [
    "### BaseTextRank vs PositionRank: Side-by-Side\n",
    "\n",
    "Let's compare both algorithms on the same text to see how position weighting affects results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same abstract, both algorithms\n",
    "base = BaseTextRank(top_n=5, language=\"en\")\n",
    "pos = PositionRank(top_n=5, language=\"en\")\n",
    "\n",
    "base_result = base.extract_keywords(abstract)\n",
    "pos_result = pos.extract_keywords(abstract)\n",
    "\n",
    "print(f\"{'BaseTextRank':<35} {'PositionRank':<35}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for i in range(5):\n",
    "    base_phrase = base_result.phrases[i]\n",
    "    pos_phrase = pos_result.phrases[i]\n",
    "    print(f\"{base_phrase.text:<35} {pos_phrase.text:<35}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparison-detailed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see which phrases are unique to each algorithm\n",
    "base_texts = {p.text for p in base_result.phrases}\n",
    "pos_texts = {p.text for p in pos_result.phrases}\n",
    "\n",
    "only_base = base_texts - pos_texts\n",
    "only_pos = pos_texts - base_texts\n",
    "both = base_texts & pos_texts\n",
    "\n",
    "print(f\"In both: {both}\")\n",
    "print(f\"Only in BaseTextRank: {only_base}\")\n",
    "print(f\"Only in PositionRank: {only_pos}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biasedtextrank-header",
   "metadata": {},
   "source": [
    "## 3. BiasedTextRank\n",
    "\n",
    "Based on [Kazemi et al. (2020)](https://aclanthology.org/2020.coling-main.144/), BiasedTextRank steers extraction toward specified focus terms.\n",
    "\n",
    "**Key parameters:**\n",
    "- `focus_terms`: List of terms to bias toward\n",
    "- `bias_weight`: How strongly to favor focus terms (higher = stronger bias)\n",
    "\n",
    "**How it works:**\n",
    "- Focus terms get an initial boost in the PageRank algorithm\n",
    "- Words connected to focus terms inherit some of this bias\n",
    "- The result emphasizes the topic you care about\n",
    "\n",
    "**Best for:** Topic-specific extraction, document filtering, aspect-based analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biasedtextrank-example",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text covering multiple topics\n",
    "tech_article = \"\"\"\n",
    "Modern web applications must balance user experience with security.\n",
    "Performance optimizations are crucial for mobile users on slow networks.\n",
    "Privacy regulations like GDPR require careful data handling and consent.\n",
    "Security vulnerabilities can expose sensitive user information.\n",
    "Caching strategies improve response times but complicate data freshness.\n",
    "Authentication systems must prevent unauthorized access while remaining\n",
    "user-friendly. Encryption protects data both in transit and at rest.\n",
    "\"\"\"\n",
    "\n",
    "# Focus on security/privacy topics\n",
    "biased = BiasedTextRank(\n",
    "    focus_terms=[\"security\", \"privacy\"],\n",
    "    bias_weight=5.0,\n",
    "    top_n=10,\n",
    "    language=\"en\"\n",
    ")\n",
    "\n",
    "result = biased.extract_keywords(tech_article)\n",
    "\n",
    "print(\"BiasedTextRank (focus: security, privacy):\")\n",
    "print(\"=\" * 50)\n",
    "for p in result.phrases:\n",
    "    print(f\"{p.rank:>2}. {p.text:<35} {p.score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bias-weight-header",
   "metadata": {},
   "source": [
    "### Effect of `bias_weight`\n",
    "\n",
    "The `bias_weight` parameter controls how strongly results favor the focus terms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bias-weight-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different bias weights\n",
    "weights = [1.0, 2.0, 5.0, 10.0]\n",
    "\n",
    "print(\"Bias Weight Comparison (focus: security, privacy)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for weight in weights:\n",
    "    biased = BiasedTextRank(\n",
    "        focus_terms=[\"security\", \"privacy\"],\n",
    "        bias_weight=weight,\n",
    "        top_n=3,\n",
    "        language=\"en\"\n",
    "    )\n",
    "    result = biased.extract_keywords(tech_article)\n",
    "    \n",
    "    print(f\"\\nbias_weight={weight}:\")\n",
    "    for p in result.phrases:\n",
    "        print(f\"  {p.text}: {p.score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bias-vs-unbiased",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare biased vs unbiased on the same text\n",
    "base = BaseTextRank(top_n=5, language=\"en\")\n",
    "biased_security = BiasedTextRank(\n",
    "    focus_terms=[\"security\", \"privacy\"],\n",
    "    bias_weight=5.0,\n",
    "    top_n=5,\n",
    "    language=\"en\"\n",
    ")\n",
    "biased_perf = BiasedTextRank(\n",
    "    focus_terms=[\"performance\", \"speed\", \"cache\"],\n",
    "    bias_weight=5.0,\n",
    "    top_n=5,\n",
    "    language=\"en\"\n",
    ")\n",
    "\n",
    "base_result = base.extract_keywords(tech_article)\n",
    "security_result = biased_security.extract_keywords(tech_article)\n",
    "perf_result = biased_perf.extract_keywords(tech_article)\n",
    "\n",
    "print(f\"{'Unbiased':<25} {'Security Focus':<25} {'Performance Focus':<25}\")\n",
    "print(\"=\" * 75)\n",
    "for i in range(5):\n",
    "    print(f\"{base_result.phrases[i].text:<25} \"\n",
    "          f\"{security_result.phrases[i].text:<25} \"\n",
    "          f\"{perf_result.phrases[i].text:<25}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focus-per-call",
   "metadata": {},
   "source": [
    "### Dynamic Focus Terms\n",
    "\n",
    "You can also pass `focus_terms` per-call, which is useful when processing multiple documents with different topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "per-call-focus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create extractor with default focus\n",
    "extractor = BiasedTextRank(\n",
    "    focus_terms=[\"default\"],  # Placeholder\n",
    "    bias_weight=5.0,\n",
    "    top_n=5,\n",
    "    language=\"en\"\n",
    ")\n",
    "\n",
    "# Override focus_terms per call\n",
    "topics = [\n",
    "    [\"security\", \"encryption\"],\n",
    "    [\"performance\", \"caching\"],\n",
    "    [\"user\", \"experience\"]\n",
    "]\n",
    "\n",
    "for focus in topics:\n",
    "    result = extractor.extract_keywords(tech_article, focus_terms=focus)\n",
    "    print(f\"\\nFocus: {focus}\")\n",
    "    for p in result.phrases[:3]:\n",
    "        print(f\"  - {p.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "json-header",
   "metadata": {},
   "source": [
    "## JSON Batch API\n",
    "\n",
    "For processing large volumes of pre-tokenized documents, use the JSON interface:\n",
    "\n",
    "- `extract_from_json()` - Single document\n",
    "- `extract_batch_from_json()` - Multiple documents\n",
    "\n",
    "This is particularly useful when:\n",
    "- You've already tokenized with spaCy or another NLP library\n",
    "- You're processing many documents in batch\n",
    "- You need fine-grained control over tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "json-single",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from rapid_textrank import extract_from_json\n",
    "\n",
    "# Single document with pre-tokenized input\n",
    "doc = {\n",
    "    \"tokens\": [\n",
    "        {\"text\": \"Machine\", \"lemma\": \"machine\", \"pos\": \"NOUN\",\n",
    "         \"start\": 0, \"end\": 7, \"sentence_idx\": 0, \"token_idx\": 0, \"is_stopword\": False},\n",
    "        {\"text\": \"learning\", \"lemma\": \"learning\", \"pos\": \"NOUN\",\n",
    "         \"start\": 8, \"end\": 16, \"sentence_idx\": 0, \"token_idx\": 1, \"is_stopword\": False},\n",
    "        {\"text\": \"is\", \"lemma\": \"be\", \"pos\": \"AUX\",\n",
    "         \"start\": 17, \"end\": 19, \"sentence_idx\": 0, \"token_idx\": 2, \"is_stopword\": True},\n",
    "        {\"text\": \"transforming\", \"lemma\": \"transform\", \"pos\": \"VERB\",\n",
    "         \"start\": 20, \"end\": 32, \"sentence_idx\": 0, \"token_idx\": 3, \"is_stopword\": False},\n",
    "        {\"text\": \"industries\", \"lemma\": \"industry\", \"pos\": \"NOUN\",\n",
    "         \"start\": 33, \"end\": 43, \"sentence_idx\": 0, \"token_idx\": 4, \"is_stopword\": False},\n",
    "    ],\n",
    "    \"config\": {\n",
    "        \"top_n\": 5,\n",
    "        \"window_size\": 4,\n",
    "        \"damping\": 0.85\n",
    "    }\n",
    "}\n",
    "\n",
    "result_json = extract_from_json(json.dumps(doc))\n",
    "result = json.loads(result_json)\n",
    "\n",
    "print(\"Single document result:\")\n",
    "for phrase in result[\"phrases\"]:\n",
    "    print(f\"  {phrase['text']}: {phrase['score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "json-batch",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rapid_textrank import extract_batch_from_json\n",
    "\n",
    "# Batch processing multiple documents\n",
    "docs = [\n",
    "    {\n",
    "        \"tokens\": [\n",
    "            {\"text\": \"Deep\", \"lemma\": \"deep\", \"pos\": \"ADJ\",\n",
    "             \"start\": 0, \"end\": 4, \"sentence_idx\": 0, \"token_idx\": 0, \"is_stopword\": False},\n",
    "            {\"text\": \"learning\", \"lemma\": \"learning\", \"pos\": \"NOUN\",\n",
    "             \"start\": 5, \"end\": 13, \"sentence_idx\": 0, \"token_idx\": 1, \"is_stopword\": False},\n",
    "            {\"text\": \"models\", \"lemma\": \"model\", \"pos\": \"NOUN\",\n",
    "             \"start\": 14, \"end\": 20, \"sentence_idx\": 0, \"token_idx\": 2, \"is_stopword\": False},\n",
    "        ],\n",
    "        \"config\": {\"top_n\": 3}\n",
    "    },\n",
    "    {\n",
    "        \"tokens\": [\n",
    "            {\"text\": \"Neural\", \"lemma\": \"neural\", \"pos\": \"ADJ\",\n",
    "             \"start\": 0, \"end\": 6, \"sentence_idx\": 0, \"token_idx\": 0, \"is_stopword\": False},\n",
    "            {\"text\": \"networks\", \"lemma\": \"network\", \"pos\": \"NOUN\",\n",
    "             \"start\": 7, \"end\": 15, \"sentence_idx\": 0, \"token_idx\": 1, \"is_stopword\": False},\n",
    "            {\"text\": \"process\", \"lemma\": \"process\", \"pos\": \"VERB\",\n",
    "             \"start\": 16, \"end\": 23, \"sentence_idx\": 0, \"token_idx\": 2, \"is_stopword\": False},\n",
    "            {\"text\": \"data\", \"lemma\": \"data\", \"pos\": \"NOUN\",\n",
    "             \"start\": 24, \"end\": 28, \"sentence_idx\": 0, \"token_idx\": 3, \"is_stopword\": False},\n",
    "        ],\n",
    "        \"config\": {\"top_n\": 3}\n",
    "    }\n",
    "]\n",
    "\n",
    "results_json = extract_batch_from_json(json.dumps(docs))\n",
    "results = json.loads(results_json)\n",
    "\n",
    "print(\"Batch results:\")\n",
    "for i, result in enumerate(results):\n",
    "    print(f\"\\nDocument {i}:\")\n",
    "    for phrase in result[\"phrases\"]:\n",
    "        print(f\"  - {phrase['text']} ({phrase['score']:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decision-guide",
   "metadata": {},
   "source": [
    "## Decision Guide: Which Variant to Use?\n",
    "\n",
    "```\n",
    "                                START\n",
    "                                  │\n",
    "                                  ▼\n",
    "                    ┌─────────────────────────┐\n",
    "                    │ Do you have specific    │\n",
    "                    │ topics to focus on?     │\n",
    "                    └─────────────────────────┘\n",
    "                         │              │\n",
    "                        YES             NO\n",
    "                         │              │\n",
    "                         ▼              ▼\n",
    "               ┌──────────────┐  ┌─────────────────────────┐\n",
    "               │ BiasedTextRank│  │ Is key info at the     │\n",
    "               │              │  │ beginning of the doc?   │\n",
    "               └──────────────┘  └─────────────────────────┘\n",
    "                                       │              │\n",
    "                                      YES             NO\n",
    "                                       │              │\n",
    "                                       ▼              ▼\n",
    "                              ┌──────────────┐ ┌──────────────┐\n",
    "                              │ PositionRank │ │ BaseTextRank │\n",
    "                              └──────────────┘ └──────────────┘\n",
    "```\n",
    "\n",
    "### Recommendations by Document Type\n",
    "\n",
    "| Document Type | Recommended Variant | Why |\n",
    "|---------------|---------------------|-----|\n",
    "| Blog posts, articles | BaseTextRank | General content, no position bias needed |\n",
    "| Academic papers | PositionRank | Key terms in title/abstract |\n",
    "| News articles | PositionRank | Lead paragraphs contain key info |\n",
    "| Product reviews | BiasedTextRank | Focus on features you care about |\n",
    "| Support tickets | BiasedTextRank | Focus on problem categories |\n",
    "| Legal documents | BaseTextRank | Important terms throughout |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "next-steps",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- **[03_explain_algorithm.ipynb](03_explain_algorithm.ipynb)** - Visual explanation of how TextRank works internally\n",
    "- **[04_benchmarks.ipynb](04_benchmarks.ipynb)** - Performance comparison with pytextrank"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
