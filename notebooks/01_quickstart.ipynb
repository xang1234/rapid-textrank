{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title",
   "metadata": {},
   "source": [
    "# rapid_textrank Quick Start\n",
    "\n",
    "This notebook demonstrates the basics of `rapid_textrank`, a high-performance TextRank implementation in Rust with Python bindings.\n",
    "\n",
    "**What you'll learn:**\n",
    "- How to extract keywords from text\n",
    "- Understanding `Phrase` objects and their attributes\n",
    "- Configuring the algorithm with `TextRankConfig`\n",
    "- Multi-language support\n",
    "- Optional spaCy integration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "install-header",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "Install `rapid_textrank` from PyPI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "install",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q rapid_textrank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "basic-header",
   "metadata": {},
   "source": [
    "## Basic Usage\n",
    "\n",
    "The simplest way to extract keywords is with the `extract_keywords()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "basic-usage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neural networks: 0.1375\n",
      "artificial intelligence: 0.1354\n",
      "subset: 0.0754\n",
      "improve: 0.0738\n",
      "learn: 0.0738\n"
     ]
    }
   ],
   "source": [
    "from rapid_textrank import extract_keywords\n",
    "\n",
    "text = \"\"\"\n",
    "Machine learning is a subset of artificial intelligence that enables\n",
    "systems to learn and improve from experience. Deep learning, a type of\n",
    "machine learning, uses neural networks with many layers.\n",
    "\"\"\"\n",
    "\n",
    "# Extract the top 5 keywords\n",
    "keywords = extract_keywords(text, top_n=5, language=\"en\")\n",
    "\n",
    "for phrase in keywords:\n",
    "    print(f\"{phrase.text}: {phrase.score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phrase-header",
   "metadata": {},
   "source": [
    "## Understanding Results: The `Phrase` Object\n",
    "\n",
    "Each keyword is returned as a `Phrase` object with several useful attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "phrase-attributes",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phrase attributes:\n",
      "  text:  'neural networks'              # The original phrase text\n",
      "  lemma: 'neural network'               # Lemmatized (base) form\n",
      "  score: 0.1375                         # TextRank importance score\n",
      "  rank:  1                              # 1-indexed ranking position\n",
      "  count: 1                              # Number of occurrences in text\n"
     ]
    }
   ],
   "source": [
    "# Let's examine the first phrase in detail\n",
    "phrase = keywords[0]\n",
    "\n",
    "print(\"Phrase attributes:\")\n",
    "print(f\"  text:  {phrase.text!r:30} # The original phrase text\")\n",
    "print(f\"  lemma: {phrase.lemma!r:30} # Lemmatized (base) form\")\n",
    "print(f\"  score: {phrase.score:<30.4f} # TextRank importance score\")\n",
    "print(f\"  rank:  {phrase.rank:<30} # 1-indexed ranking position\")\n",
    "print(f\"  count: {phrase.count:<30} # Number of occurrences in text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "phrase-table",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank   Text                                Score      Count \n",
      "------------------------------------------------------------\n",
      "1      neural networks                     0.1375     1     \n",
      "2      artificial intelligence             0.1354     1     \n",
      "3      subset                              0.0754     1     \n",
      "4      improve                             0.0738     1     \n",
      "5      learn                               0.0738     1     \n"
     ]
    }
   ],
   "source": [
    "# View all keywords as a table\n",
    "print(f\"{'Rank':<6} {'Text':<35} {'Score':<10} {'Count':<6}\")\n",
    "print(\"-\" * 60)\n",
    "for p in keywords:\n",
    "    print(f\"{p.rank:<6} {p.text:<35} {p.score:<10.4f} {p.count:<6}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config-header",
   "metadata": {},
   "source": [
    "## Configuration with `TextRankConfig`\n",
    "\n",
    "For more control over the algorithm, use `TextRankConfig` with the class-based API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "config-example",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged: True\n",
      "Iterations: 23\n",
      "Top phrases:\n",
      "  1. neural networks: 0.1375\n",
      "  2. artificial intelligence: 0.1354\n",
      "  3. subset: 0.0754\n",
      "  4. improve: 0.0738\n",
      "  5. learn: 0.0738\n"
     ]
    }
   ],
   "source": [
    "from rapid_textrank import TextRankConfig, BaseTextRank\n",
    "\n",
    "# Create a custom configuration (only overriding a few defaults)\n",
    "config = TextRankConfig(\n",
    "    top_n=10,\n",
    "    score_aggregation=\"sum\",\n",
    "    language=\"en\",\n",
    ")\n",
    "\n",
    "# Create an extractor with the config\n",
    "extractor = BaseTextRank(config=config)\n",
    "\n",
    "# Extract keywords\n",
    "result = extractor.extract_keywords(text)\n",
    "\n",
    "print(f\"Converged: {result.converged}\")\n",
    "print(f\"Iterations: {result.iterations}\")\n",
    "print(f\"Top phrases:\")\n",
    "for p in result.phrases[:5]:\n",
    "    print(f\"  {p.rank}. {p.text}: {p.score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config-params",
   "metadata": {},
   "source": [
    "### Key Configuration Parameters\n",
    "\n",
    "| Parameter | Default | Description |\n",
    "|-----------|---------|-------------|\n",
    "| `damping` | 0.85 | PageRank damping factor. Higher = more weight to graph structure |\n",
    "| `window_size` | 4 | Co-occurrence window. Larger = more connections between distant words |\n",
    "| `min_phrase_length` | 1 | Allow single words as phrases |\n",
    "| `max_phrase_length` | 4 | Maximum words in a keyphrase |\n",
    "| `score_aggregation` | \"sum\" | How to combine word scores: sum, mean, max, or rms |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aggregation-demo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score Aggregation Comparison (top 3 phrases):\n",
      "============================================================\n",
      "\n",
      "SUM:\n",
      "  neural networks: 0.1375\n",
      "  artificial intelligence: 0.1354\n",
      "  subset: 0.0754\n",
      "\n",
      "MEAN:\n",
      "  subset: 0.0754\n",
      "  improve: 0.0738\n",
      "  learn: 0.0738\n",
      "\n",
      "MAX:\n",
      "  neural networks: 0.0778\n",
      "  artificial intelligence: 0.0759\n",
      "  subset: 0.0754\n",
      "\n",
      "RMS:\n",
      "  subset: 0.0754\n",
      "  improve: 0.0738\n",
      "  learn: 0.0738\n"
     ]
    }
   ],
   "source": [
    "# Compare different score aggregation methods\n",
    "aggregation_methods = [\"sum\", \"mean\", \"max\", \"rms\"]\n",
    "\n",
    "print(\"Score Aggregation Comparison (top 3 phrases):\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for method in aggregation_methods:\n",
    "    config = TextRankConfig(score_aggregation=method, top_n=3, language=\"en\")\n",
    "    extractor = BaseTextRank(config=config)\n",
    "    result = extractor.extract_keywords(text)\n",
    "    \n",
    "    print(f\"\\n{method.upper()}:\")\n",
    "    for p in result.phrases:\n",
    "        print(f\"  {p.text}: {p.score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "multilang-header",
   "metadata": {},
   "source": [
    "## Multi-Language Support\n",
    "\n",
    "`rapid_textrank` supports stopword filtering for 18 languages:\n",
    "\n",
    "| Code | Language | Code | Language | Code | Language |\n",
    "|------|----------|------|----------|------|----------|\n",
    "| `en` | English | `de` | German | `fr` | French |\n",
    "| `es` | Spanish | `it` | Italian | `pt` | Portuguese |\n",
    "| `nl` | Dutch | `ru` | Russian | `sv` | Swedish |\n",
    "| `no` | Norwegian | `da` | Danish | `fi` | Finnish |\n",
    "| `hu` | Hungarian | `tr` | Turkish | `pl` | Polish |\n",
    "| `ar` | Arabic | `zh` | Chinese | `ja` | Japanese |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "german-example",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "German keywords:\n",
      "  1. Learning verwendet neuronale Netze: 0.2865\n",
      "  2. Maschinelles Lernen: 0.1130\n",
      "  3. Technologie ermöglicht: 0.1130\n",
      "  4. künstlichen Intelligenz: 0.1130\n",
      "  5. Computern: 0.0866\n"
     ]
    }
   ],
   "source": [
    "# German example\n",
    "german_text = \"\"\"\n",
    "Maschinelles Lernen ist ein Teilgebiet der künstlichen Intelligenz.\n",
    "Deep Learning verwendet neuronale Netze mit vielen Schichten.\n",
    "Diese Technologie ermöglicht es Computern, aus Erfahrung zu lernen.\n",
    "\"\"\"\n",
    "\n",
    "keywords_de = extract_keywords(german_text, top_n=5, language=\"de\")\n",
    "\n",
    "print(\"German keywords:\")\n",
    "for p in keywords_de:\n",
    "    print(f\"  {p.rank}. {p.text}: {p.score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "french-example",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "French keywords:\n",
      "  1. neurones profonds permettent l'analyse: 0.2914\n",
      "  2. secteurs industriels: 0.1250\n",
      "  3. technologies transforment: 0.1250\n",
      "  4. L'apprentissage automatique: 0.1130\n",
      "  5. l'intelligence artificielle: 0.1130\n"
     ]
    }
   ],
   "source": [
    "# French example\n",
    "french_text = \"\"\"\n",
    "L'apprentissage automatique est une branche de l'intelligence artificielle.\n",
    "Les réseaux de neurones profonds permettent l'analyse de données complexes.\n",
    "Ces technologies transforment de nombreux secteurs industriels.\n",
    "\"\"\"\n",
    "\n",
    "keywords_fr = extract_keywords(french_text, top_n=5, language=\"fr\")\n",
    "\n",
    "print(\"French keywords:\")\n",
    "for p in keywords_fr:\n",
    "    print(f\"  {p.rank}. {p.text}: {p.score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spacy-header",
   "metadata": {},
   "source": [
    "## Optional: spaCy Integration\n",
    "\n",
    "If you use spaCy, `rapid_textrank` can integrate as a pipeline component. This lets you use spaCy's superior tokenization with rapid_textrank's fast extraction.\n",
    "\n",
    "First, install the required dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "spacy-install",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting en-core-web-sm==3.8.0\n",
      "  Using cached https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "# Uncomment to install spaCy dependencies\n",
    "%pip install -q spacy\n",
    "import sys\n",
    "!{sys.executable} -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "spacy-demo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keywords via spaCy pipeline:\n",
      "  1. machine learning: 0.2156\n",
      "  2. Deep learning: 0.1674\n",
      "  3. artificial intelligence: 0.1228\n",
      "  4. neural networks: 0.1167\n",
      "  5. systems: 0.0670\n"
     ]
    }
   ],
   "source": [
    "# spaCy integration example\n",
    "try:\n",
    "    import spacy\n",
    "    import rapid_textrank.spacy_component  # Registers the pipeline factory\n",
    "    \n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    nlp.add_pipe(\"rapid_textrank\")\n",
    "    \n",
    "    doc = nlp(text)\n",
    "    \n",
    "    print(\"Keywords via spaCy pipeline:\")\n",
    "    for phrase in doc._.phrases[:5]:\n",
    "        print(f\"  {phrase.rank}. {phrase.text}: {phrase.score:.4f}\")\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"spaCy not installed. This is optional - rapid_textrank works great on its own!\")\n",
    "except OSError:\n",
    "    import sys\n",
    "    print(f\"spaCy model not found. Run: {sys.executable} -m spacy download en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1885a38",
   "metadata": {},
   "source": [
    "## TopicRank (Topic Clustering)\n",
    "\n",
    "TopicRank groups similar keyphrases into topics and ranks the topics instead of individual phrases. \n",
    "For apples-to-apples comparison with pytextrank, this example uses spaCy tokens.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64f7ee20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TopicRank phrases (rapid_textrank):\n",
      "  1. Machine learning: 0.4312\n",
      "  2. Deep learning: 0.1674\n",
      "  3. artificial intelligence: 0.1228\n",
      "  4. neural networks: 0.1167\n",
      "  5. systems: 0.0670\n"
     ]
    }
   ],
   "source": [
    "# TopicRank using spaCy tokens (shared tokenization)\n",
    "try:\n",
    "    import json\n",
    "    import spacy\n",
    "    from rapid_textrank import extract_from_json\n",
    "\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    doc = nlp(text)\n",
    "\n",
    "    tokens = []\n",
    "    for sent_idx, sent in enumerate(doc.sents):\n",
    "        for token in sent:\n",
    "            tokens.append({\n",
    "                'text': token.text,\n",
    "                'lemma': token.lemma_,\n",
    "                'pos': token.pos_,\n",
    "                'start': token.idx,\n",
    "                'end': token.idx + len(token.text),\n",
    "                'sentence_idx': sent_idx,\n",
    "                'token_idx': token.i,\n",
    "                'is_stopword': token.is_stop,\n",
    "            })\n",
    "\n",
    "    payload = {\n",
    "        'tokens': tokens,\n",
    "        'variant': 'topic_rank',\n",
    "        'config': {\n",
    "            'top_n': 5,\n",
    "            'language': 'en',\n",
    "        },\n",
    "    }\n",
    "\n",
    "    result = json.loads(extract_from_json(json.dumps(payload)))\n",
    "\n",
    "    print('TopicRank phrases (rapid_textrank):')\n",
    "    for p in result['phrases'][:5]:\n",
    "        print(f\"  {p['rank']}. {p['text']}: {p['score']:.4f}\")\n",
    "\n",
    "except ImportError:\n",
    "    print('spaCy not installed. Install it to run this example.')\n",
    "except OSError:\n",
    "    import sys\n",
    "    print(f'spaCy model not found. Run: {sys.executable} -m spacy download en_core_web_sm')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "next-steps",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Now that you know the basics, explore more in the other notebooks:\n",
    "\n",
    "1. **[02_algorithm_variants.ipynb](02_algorithm_variants.ipynb)** - Deep dive into BaseTextRank, PositionRank, and BiasedTextRank\n",
    "2. **[03_explain_algorithm.ipynb](03_explain_algorithm.ipynb)** - Visual explanation of how TextRank works\n",
    "3. **[04_benchmarks.ipynb](04_benchmarks.ipynb)** - Performance comparison with pytextrank\n",
    "\n",
    "### Resources\n",
    "\n",
    "- [GitHub Repository](https://github.com/xang1234/rapid-textrank)\n",
    "- [Original TextRank Paper](https://aclanthology.org/W04-3252/) (Mihalcea & Tarau, 2004)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
